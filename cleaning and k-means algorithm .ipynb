{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29e1dec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndataset of customer information for an online clothing store,\\nincluding age, gender, income, and purchase history. \\nWe want to group these customers into different clusters\\nbased on their purchasing behavior.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "dataset of customer information for an online clothing store,\n",
    "including age, gender, income, and purchase history. \n",
    "We want to group these customers into different clusters\n",
    "based on their purchasing behavior.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb08ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1ab316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate false data with deliberate errors\n",
    "data = pd.DataFrame({\n",
    "    'Age': np.random.choice([25, 30, 35, 40, 45, 50, 55, 60, 65, 70], 40000),\n",
    "    'Income': np.random.choice([25000, 35000, 45000, 55000, 65000, 75000, 85000, 95000], 40000),\n",
    "    'SpendingScore': np.random.choice([10, 20, 30, 40, 50, 60, 70, 80, 90, 100], 40000)\n",
    "})\n",
    "\n",
    "# Introduce deliberate errors to practice some data cleaning \n",
    "data.loc[10:20, 'Age'] = -1  # Invalid negative age values\n",
    "data.loc[30:40, 'Income'] = 'unknown'  # Invalid string values for income\n",
    "data.loc[50:60, 'SpendingScore'] = np.nan  # Missing values for spending score\n",
    "\n",
    "# Save the dataset as a CSV file\n",
    "data.to_csv('customer_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d132d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and preprocess data\n",
    "# Handling Missing Data (nan) \n",
    "# easy way is to drop the number or fill it with 0 or...\n",
    "def handle_missing_values(data, strategy='drop', fill_value=0,delete_unknown=True, delete_negative_one=True):\n",
    "    if strategy == 'drop':\n",
    "        # Drop rows with any missing values\n",
    "        data_cleaned = data.dropna()\n",
    "    elif strategy == 'fill':\n",
    "        # Fill missing values with the specified fill_value\n",
    "        if fill_value is None:\n",
    "            raise ValueError(\"fill_value must be provided when strategy is 'fill'\")\n",
    "        # Fill missing values with the specified fill_value\n",
    "        data_cleaned = data.fillna(fill_value)\n",
    "    elif strategy == 'mean':\n",
    "        # Fill missing values with the mean of each column\n",
    "        data_cleaned = data.fillna(data.mean())\n",
    "    else:\n",
    "        raise ValueError(\"Invalid strategy. Options: 'drop', 'fill'\")\n",
    "    # Delete rows with unknown values    \n",
    "    if delete_unknown:\n",
    "        data_cleaned = data_cleaned[~data_cleaned.isin(['unknown', 'Unknown', 'UNKNOWN'])]\n",
    "\n",
    "    # Delete rows with -1 values\n",
    "    if delete_negative_one:\n",
    "        data_cleaned = data_cleaned[data_cleaned != -1].dropna()\n",
    "\n",
    "    return data_cleaned\n",
    "\n",
    "\n",
    "# we can Create a linear regression model to predict missing values using KNN and using scikit library \n",
    "\n",
    "# Removing Duplicates: Duplicated data can be identified and removed to ensure data integrity. \n",
    "def remove_duplicates(data, columns=None, keep='first'):\n",
    "    # Remove duplicates based on specified columns\n",
    "    data_cleaned = data.drop_duplicates(subset=columns, keep=keep)\n",
    "\n",
    "    return data_cleaned\n",
    "\n",
    "\n",
    "datacleaned =handle_missing_values(data)\n",
    "datacleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed7d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a data quality tester to determine the quality of the cleaning function\n",
    "def test_data_quality(data):\n",
    "    # Check for NaN values\n",
    "    nan_count = data.isna().sum().sum()\n",
    "    if nan_count > 0:\n",
    "        print(f\"Test failed: {nan_count} NaN values found in the DataFrame.\")\n",
    "        return\n",
    "\n",
    "    # Check for unknown values\n",
    "    unknown_values = ['unknown', 'Unknown', 'UNKNOWN']\n",
    "    unknown_count = data.isin(unknown_values).sum().sum()\n",
    "    if unknown_count > 0:\n",
    "        print(f\"Test failed: {unknown_count} unknown values found in the DataFrame.\")\n",
    "        return\n",
    "\n",
    "    # Check for -1 values\n",
    "    negative_one_count = (data == -1).sum().sum()\n",
    "    if negative_one_count > 0:\n",
    "        print(f\"Test failed: {negative_one_count} -1 values found in the DataFrame.\")\n",
    "        return\n",
    "\n",
    "    print(\"Data quality test passed successfully!\")\n",
    "    \n",
    "    \n",
    "    \n",
    "test_data_quality(datacleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881f7fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1776c5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82274b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# we'll extract the relevant features from the dataset and\n",
    "# normalize them to have a mean of 0 and a standard deviation of 1:\n",
    "# Feature scaling ensures that features have similar scales to prevent domination by one feature due to magnitude differences.\n",
    "# for machine learning purpose for later \n",
    "'''\n",
    "X = datacleaned[['Age', 'Income', 'SpendingScore']].values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739c9f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then, we'll use the k-means algorithm to cluster \n",
    "#the data into a specified number of clusters (in this case, \n",
    "#let's say 5):\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dd1db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can then get the cluster assignments for each data point:\n",
    "labels = kmeans.labels_\n",
    "\n",
    "#We can also get the coordinates of the cluster centers:\n",
    "centroids = kmeans.cluster_centers_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292acb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the clusters using a scatter plot:\n",
    "plt.scatter(X[:,0], X[:,1], c=labels, cmap='rainbow')\n",
    "plt.scatter(centroids[:,0], centroids[:,1], marker='x', s=200, linewidths=3, color='black')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Income')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a305e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
